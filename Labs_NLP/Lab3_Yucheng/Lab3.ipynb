{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lab 3: Language Modeling\n",
    "=============\n",
    "Yucheng Jin (yucheng9)\n",
    "=============\n",
    "In this problem set, you will train a language model. You will:\n",
    "\n",
    "- Train an n-gram language model.\n",
    "- Use that language model to generate representative sentences.\n",
    "- Study the effect of training data size, and language model complexity (n-gram size), on the modeling capacity of a language model.\n",
    "\n",
    "- **To submit this assignment, compress the whole directory using tar, and submit the tarball ```lab2-submission.tgz``` on Compass.**\n",
    "\n",
    "Total points: 100 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Setup\n",
    "\n",
    "In order to develop this assignment, you will need [python 3.6](https://www.python.org/downloads/) and the following libraries. Most if not all of these are part of [anaconda](https://www.continuum.io/downloads), so a good starting point would be to install that.\n",
    "\n",
    "- [jupyter](http://jupyter.readthedocs.org/en/latest/install.html)\n",
    "- [nosetests](https://nose.readthedocs.org/en/latest/)\n",
    "- [nltk](https://www.nltk.org)\n",
    "\n",
    "Here is some help on installing packages in python: https://packaging.python.org/installing/. You can use ```pip --user``` to install locally without sudo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from importlib import reload\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My Python version\n",
      "python: 3.7.3 (default, Mar 27 2019, 16:54:48) \n",
      "[Clang 4.0.1 (tags/RELEASE_401/final)]\n"
     ]
    }
   ],
   "source": [
    "print('My Python version')\n",
    "\n",
    "print('python: {}'.format(sys.version))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nose\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My library versions\n",
      "nose: 1.3.7\n",
      "nltk: 3.4.4\n"
     ]
    }
   ],
   "source": [
    "print('My library versions')\n",
    "\n",
    "print('nose: {}'.format(nose.__version__))\n",
    "print('nltk: {}'.format(nltk.__version__))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To test whether your libraries are the right version, run:\n",
    "\n",
    "`nosetests tests/test_environment.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.001s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_environment.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Training a language model\n",
    "\n",
    "Let us first train a 3-gram language model using the language modeling toolkit: kenlm. To train a language model, all we need is a monolingual corpus, which we will get using nltk.\n",
    "\n",
    "Total: 40 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us first extract from nltk's reuters corpus, 2 corpora of 2 different domains, the food industry and the natural resources industry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "food = ['barley', 'castor-oil', 'cocoa', 'coconut', 'coconut-oil', 'coffee', 'copra-cake''grain', 'groundnut', 'groundnut-oil', 'potato''soy-meal', 'soy-oil', 'soybean', 'sugar', 'sun-meal', 'sun-oil', 'sunseed', 'tea', 'veg-oil', 'wheat']\n",
    "natural_resources = ['alum', 'fuel', 'gas', 'gold', 'iron-steel', 'lead', 'nat-gas', 'palladium', 'propane', 'tin', 'zinc']\n",
    "corpus = nltk.corpus.reuters\n",
    "food_corpus = corpus.raw(categories=food)\n",
    "natr_corpus = corpus.raw(categories=natural_resources)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization\n",
    "\n",
    "Your first task is to tokenize the raw text into a list of sentences, which are in turn a list of words. No need for any other kind of preprocessing such as lowercasing.\n",
    "\n",
    "- **Deliverable 1.1**: Complete the function `ece365lib.train.tokenize`. (5 points)\n",
    "- **Test**: `nose tests/test_train.py:test_d1_1_tk`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ece365lib import train\n",
    "reload(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/yuchengjin/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_corpus_tk = train.tokenize_corpus(food_corpus)\n",
    "natr_corpus_tk = train.tokenize_corpus(natr_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 2.601s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_train.py:test_d1_1_tk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Padding\n",
    "\n",
    "Your second task is to pad your sentences with the start-of-sentence symbol and end-of-sentence symbol. These symbols are necessary to model the probability of words that usually start a sentence and those that usually end a sentence.\n",
    "\n",
    "- **Deliverable 1.2**: Complete the function `ece365lib.train.pad`. (5 points)\n",
    "- **Test**: `nosetests tests/test_train.py:test_d1_2_pad`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_corpus_tk_pd = train.pad_corpus(food_corpus_tk)\n",
    "natr_corpus_tk_pd = train.pad_corpus(natr_corpus_tk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 2.563s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_train.py:test_d1_2_pad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train-Test Split\n",
    "\n",
    "Your third task is to split the corpora into train, for training the language model, and test, for testing the language model. We will go with the traditional 80% (train), 20% (test) split. The first floor(0.8*nsents) should constitute the training corpus, and the rest should constitute the test corpus.\n",
    "\n",
    "- **Deliverable 1.3**: Complete the function `ece365lib.train.split_corpus`. (10 points)\n",
    "- **Test**: `nosetests tests/test_train.py:test_d1_3_spc`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_corpus_tr, food_corpus_te = train.split_corpus(food_corpus_tk_pd)\n",
    "natr_corpus_tr, natr_corpus_te = train.split_corpus(natr_corpus_tk_pd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 2.817s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_train.py:test_d1_3_spc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting into n-grams\n",
    "\n",
    "Your fourth task is to count n-grams in the text up to a specific order.\n",
    "\n",
    "- **Deliverable 1.4**: Complete the function `ece365lib.train.count_ngrams`. (10 points)\n",
    "- **Test**: `nosetests tests/test_train.py:test_d1_4_cn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_ngrams, food_vocab = train.count_ngrams(food_corpus_tr, 3)\n",
    "natr_ngrams, natr_vocab = train.count_ngrams(natr_corpus_tr, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 6.443s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_train.py:test_d1_4_cn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating n-gram probability\n",
    "\n",
    "Your last task in this part of the problem set is to estimate the n-gram probabilities p(w_i|w_{i-n+1}, w_{i-n+2}, .., w_{i-1}). For the purposes of this exercise we use maximum likelihood estimate and perform no smoothing. \n",
    "\n",
    "- **Deliverable 1.5**: Complete the function `ece365lib.train.estimate`. (10 points)\n",
    "- **Test**: `nosetests tests/test_train.py:test_d1_5_es`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "print(train.estimate(food_ngrams, ['palm'], ['producer', 'of']))\n",
    "print(train.estimate(natr_ngrams, ['basis'], ['tested', 'the']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 6.407s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!nosetests tests/test_train.py:test_d1_5_es"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a language model\n",
    "\n",
    "For the sake of simplicity, and for the purposes of later parts in this problem set, we use nltk's lm module to train a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.lm import Laplace\n",
    "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
    "\n",
    "food_train, food_vocab = padded_everygram_pipeline(3, food_corpus_tk[:int(0.8*len(food_corpus_tk))])\n",
    "natr_train, natr_vocab = padded_everygram_pipeline(3, natr_corpus_tk[:int(0.8*len(natr_corpus_tk))])\n",
    "\n",
    "food_test = sum([['<s>'] + x + ['</s>'] for x in food_corpus_tk[int(0.8*len(food_corpus_tk)):]],[])\n",
    "natr_test = sum([['<s>'] + x + ['</s>'] for x in natr_corpus_tk[int(0.8*len(natr_corpus_tk)):]],[])\n",
    "\n",
    "food_lm = Laplace(3)\n",
    "natr_lm = Laplace(3)\n",
    "\n",
    "food_lm.fit(food_train, food_vocab)\n",
    "natr_lm.fit(natr_train, natr_vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One way to see what the language model learned is to see the sentences it can generate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', 'Commenting', 'on', 'the', 'new', 'Congress', 'convenes', 'after', 'the', 'May']\n",
      "['<s>', 'Currently', ',', 'there', 'was', 'a', '15.3', 'pct', 'increase', ',']\n"
     ]
    }
   ],
   "source": [
    "n_words = 10\n",
    "print(food_lm.generate(n_words, random_seed=3))\n",
    "print(natr_lm.generate(n_words, random_seed=3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Evaluating a language model\n",
    "\n",
    "Next, we evaluate our language models using the perplexity measure, and draw conclusions on how switch of domains can affect the performance of a language model. Perplexity measures the language model capacity at predicting sentences in a test corpus.\n",
    "\n",
    "Total: 20 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 2.1**: Complete the function `ece365lib.evaluate.get_perplexity`. (10 points)\n",
    "- **Test**: `nosetests tests/test_train.py:test_d2_1_gp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ece365lib import evaluate\n",
    "reload(evaluate);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7318.4416424924275\n",
      "7309.175157015321\n",
      "5222.470200914429\n",
      "5354.495948590062\n"
     ]
    }
   ],
   "source": [
    "# This might take some time\n",
    "print(evaluate.get_perplexity(food_lm, food_test[:2500]))\n",
    "print(evaluate.get_perplexity(food_lm, natr_test[:2500]))\n",
    "print(evaluate.get_perplexity(natr_lm, natr_test[:2500]))\n",
    "print(evaluate.get_perplexity(natr_lm, food_test[:2500]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 50.581s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_train.py:test_d2_1_gp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Deliverable 2.2**: What observations can you make on the results? Is the domain shift affecting the performance of the language model? Is that always the case? What are possible explanations? (10 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**My Answer**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* My observations: the language model trained by the food industry corpus has very close perplexities on the food industry corpus test set and the natural resources industry corpus test set (one is 7318, the other is 7309); similarly, the language model trained by the natural resources industry corpus has very close perplexities on the food industry corpus test set and the natural resources industry corpus test set (one is 5354, the other is 5222).  \n",
    "\n",
    " \n",
    "* The domain shift not significantly affects the performance of the language model.  \n",
    "\n",
    "\n",
    "* This is not always the case. Perplexity can be viewed as the weighted average branching factor of a language, which is the number of possible next words that can follow any word (J & M, Chapter 3, p. 8). Because the language model is trained on the training data, it will be biased towards the training data, if the test data are similar to the training data, then the number of possible next words that can follow any word is limited since the training and test data have a lot of common characteristics. In this case, the two corpora both focus on the industry (one is food, the other is natural resources), and the contexts may have a lot in common.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data size and model complexity\n",
    "\n",
    "Let us now see how the size of the training data size and the complexity of the model we choose affects the quality of our language model.\n",
    "\n",
    "Total: 40 points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this part we'd like to see the difference between a 2-gram model and a 4-gram model, when trained on 25%, 50%, 75%, and 100% of the training corpus. \n",
    "\n",
    "- **Deliverable 3.1**: Complete the function `ece365lib.train.vary_ngram`. (40 points)\n",
    "- **Test**: `nosetests tests/test_train.py:test_d3_1_vary`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ece365lib import train\n",
    "reload(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'float'>, {2: 7387.09139428148, 3: 7428.409564676149})\n"
     ]
    }
   ],
   "source": [
    "n_gram_orders = [2, 3]\n",
    "\n",
    "train_corpus = food_corpus_tk[:int(0.8*len(food_corpus_tk))]\n",
    "test_corpus = food_corpus_tk[int(0.8*len(food_corpus_tk)): int(0.85*len(food_corpus_tk))]\n",
    "\n",
    "results = train.vary_ngram(train_corpus, test_corpus, n_gram_orders)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 1 test in 89.953s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "! nosetests tests/test_train.py:test_d3_1_vary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that the 3-gram language model actually performs worse than the 2-gram language model. This is due to the smal size of the training corpus. A 3-gram language model is actually too complex of a model for a small training size. If our training data was larger, we would be seeing the opposite."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
